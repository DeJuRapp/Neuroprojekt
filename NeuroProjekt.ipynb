{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKBvoCq6sFLJ"
      },
      "source": [
        "# Basic imports and utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PbfgCSeWsO6G"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import layer\n",
        "from neurons import RBF\n",
        "from typing import List\n",
        "import loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLnJEX22yzFJ"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpYFiq29yw9r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-tGOT28rRvg"
      },
      "source": [
        "# RBF\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pIypjUCx6VG"
      },
      "source": [
        "We choose a gau√üian activation function for a RBF neuron with it's derivatives $$y(x)=e^{-\\frac{||x - c||^2}{2\\sigma^2}}$$\n",
        "$$\\frac d{dc}y(x)=-\\frac{x - c}{\\sigma^2}e^{-\\frac{||x - c||^2}{2\\sigma^2}}$$\n",
        "$$\\frac d{dx}y(x)=\\frac{x - c}{\\sigma^2}e^{-\\frac{||x - c||^2}{2\\sigma^2}}$$\n",
        "\n",
        "The standard deviation is going to be a fixed size hyper parameter.\n",
        "## Definition of an RBF in this module\n",
        "To use the broadcasting abilities of numpy as much as possible, we design functions in a way that they can update multiple neurons at once. For this we design the data structures for our neurons in a data oriented way. For this to work, the only limit put onto our neurons is that the input dimensions should be the same for all neurons.\n",
        "\n",
        "Since we are going to work on images, and an image is a $(w, h, 3)$ float or integer array an RBF neuron needs to define the following things.\n",
        "\n",
        "c: Should be a $(k_w, k_h, k_c)$ array representing the centers for this neuron\n",
        "\n",
        "x: A subimage that should be defined by the outside function with the same dimesnions as c."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For a classic convolutional layer, it's common that we have overlapping kernels.\n",
        "\n",
        "Since we are learning using gradient decent, we need to propagate the error back through the overlapping regions and take into account the mistake made by each kernel iteration.\n",
        "\n",
        "In our case this means that\n",
        "$$ y_{i,j}=e^{-\\frac{\\sum_k\\sum_l (x_{i+k,j+l} - c_{k,l})^2}{2\\sigma^2}} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "zD8wMxFBMAvT",
        "outputId": "3de0b02d-bed9-4cf5-bb16-27a8635a5eac"
      },
      "outputs": [],
      "source": [
        "image = np.random.uniform(0, 1, size=[6, 6, 3])\n",
        "plt.figure()\n",
        "plt.imshow(image)\n",
        "l = layer.ConvolutionalLayer(image.shape, 1, 1, (3,3,3), RBF)\n",
        "l.propagate(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (1,2) (1,4) ",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6340/2016413658.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mderiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback_propagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mderiv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTRAIN_RATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback_propagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mderiv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTRAIN_RATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Giutear\\Documents\\GitHub\\Neuroprojekt\\layer.py\u001b[0m in \u001b[0;36mback_propagate\u001b[1;34m(self, derivative, train_rate)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mback_propagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mderivative\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_rate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0md_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneuron_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mback_propagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mold_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneuron_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mold_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mderivative\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneuron_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneuron_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneuron_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Giutear\\Documents\\GitHub\\Neuroprojekt\\neurons.py\u001b[0m in \u001b[0;36mback_propagate\u001b[1;34m(x, c, y, derivatives)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_neurons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mderiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSTANDARD_DEVIATION\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mderivatives\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mderiv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mderiv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,2) (1,4) "
          ]
        }
      ],
      "source": [
        "TRAIN_RATE:float = 0.1\n",
        "\n",
        "layers:List[layer.Layer] = []\n",
        "layers.append(layer.DenseLayer(2, 2, RBF))\n",
        "layers.append(layer.DenseLayer(2, 1, RBF))\n",
        "\n",
        "inputs = np.array([[0.0,0.0],[1.0,0.0],[0.0,1.0],[1.0,1.0]])\n",
        "expected = np.array([0.0,1.0,1.0,0.0])\n",
        "\n",
        "for _ in range(100):\n",
        "    order = np.arange(4)\n",
        "    np.random.shuffle(order)\n",
        "    for i in range(4):\n",
        "        current_input = inputs[order[i]].reshape((1, -1))\n",
        "        for l in layers:\n",
        "            current_input = l.propagate(current_input)\n",
        "        error = expected[order[i]] - current_input[0]\n",
        "\n",
        "        loss_i, deriv = loss.cross_entropy_loss(current_input[0], expected[order[i]])\n",
        "\n",
        "        deriv = layers[1].back_propagate(deriv, TRAIN_RATE)\n",
        "        layers[0].back_propagate(deriv, TRAIN_RATE)\n",
        "\n",
        "for i in range(4):\n",
        "    current_input = inputs[i].reshape((1, -1))\n",
        "    for l in layers:\n",
        "        current_input = l.propagate(current_input)   \n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "yLnJEX22yzFJ"
      ],
      "name": "NeuroProjekt.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "545ce24e793e1353ad1aa1d336762d198a16bd057b21e3cc4f80d78d27aa7f07"
    },
    "kernelspec": {
      "display_name": "Python 3.7.10 64-bit ('test-env': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

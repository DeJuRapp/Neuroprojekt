{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-tGOT28rRvg"
      },
      "source": [
        "# RBF\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pIypjUCx6VG"
      },
      "source": [
        "We choose a gaußian activation function for a RBF neuron with it's derivatives $$y(x)=e^{-\\sum\\limits_i\\frac{(x_i-c_i)^2}{\\sigma_i^2}}$$\n",
        "$$\\frac d{dc}y(x)=2\\sigma^2(x-c)y(x)$$\n",
        "$$\\frac d{d\\sigma}y(x)=-2(x-c)\\sigma y(x)$$\n",
        "$$\\frac d{dx}y(x)=-2\\sigma^2(x-c)y(x)$$\n",
        "\n",
        "Where $x,c,\\sigma\\in \\mathbb{R}^n$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The MNIST data set can be downloaded in *.CSV* [this](https://github.com/pjreddie/mnist-csv-png/blob/master/process_mnist.py) git repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RBF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Boolean Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import layer\n",
        "from neurons import RBF\n",
        "from typing import List\n",
        "import model\n",
        "\n",
        "TRAIN_RATE:float = 0.0001\n",
        "TRAIN:bool = True\n",
        "FIRST_LAYER_NEURONS:int = 5\n",
        "SECOND_LAYER_NEURONS:int = 10\n",
        "NUM_LABELS:int = 2\n",
        "TRAINING_REPITIONS:int = 100\n",
        "BATCH_SIZE:int = 4\n",
        "\n",
        "\n",
        "inputs = np.array([[0.0,0.0],[1.0,0.0],[0.0,1.0],[1.0,1.0]]).reshape(-1, BATCH_SIZE, 2)\n",
        "expected = np.array([[1.0, 0.0], [1.0,0.0], [0.0,1.0], [0.0,1.0]]).reshape(-1, BATCH_SIZE, NUM_LABELS)\n",
        "\n",
        "layers:List[layer.DenseLayer] = []\n",
        "layers.append(layer.DenseLayer(2, FIRST_LAYER_NEURONS, RBF()))\n",
        "#features = layers[-1].subsample_EM_init(inputs.reshape(-1,2)[:min(FIRST_LAYER_NEURONS, 4)], expected.reshape(-1,NUM_LABELS)[:min(FIRST_LAYER_NEURONS, 4)])\n",
        "layers.append(layer.DenseLayer(FIRST_LAYER_NEURONS, SECOND_LAYER_NEURONS, RBF()))\n",
        "#features = layers[-1].subsample_EM_init(features[:min(FIRST_LAYER_NEURONS, SECOND_LAYER_NEURONS)], expected.reshape(-1,NUM_LABELS)[:min(FIRST_LAYER_NEURONS, SECOND_LAYER_NEURONS)])\n",
        "layers.append(layer.DenseLayer(SECOND_LAYER_NEURONS, NUM_LABELS, RBF()))\n",
        "#features = layers[-1].subsample_EM_init(features[:min(NUM_LABELS, SECOND_LAYER_NEURONS)], expected.reshape(-1,NUM_LABELS)[:min(NUM_LABELS, SECOND_LAYER_NEURONS)])\n",
        "\n",
        "m = model.Model(layers)\n",
        "\n",
        "original_c = layers[0].neurons.c\n",
        "\n",
        "if TRAIN:\n",
        "    \n",
        "    m.train(inputs, expected, TRAINING_REPITIONS)\n",
        "\n",
        "    plt.plot(m.losses, label='Loss')\n",
        "    plt.legend()\n",
        "\n",
        "predicted_output = m.predict(inputs.reshape(1, 4, 2))\n",
        "\n",
        "for i, output in enumerate(predicted_output.reshape(-1, NUM_LABELS)):\n",
        "    out_string = \"\"\n",
        "    for j in range(NUM_LABELS):\n",
        "        out_string += f\"{predicted_output[0,i,j]:.2f}, \"\n",
        "\n",
        "    print(f\"Output: [{out_string}]\\tExpected: {expected.reshape(-1, NUM_LABELS)[i]}\")\n",
        "\n",
        "pts = np.empty((FIRST_LAYER_NEURONS, 2))\n",
        "colours = np.empty((FIRST_LAYER_NEURONS,3))\n",
        "pts = layers[0].neurons.c\n",
        "colours[:] = np.array([0.0,0.0,1.0])\n",
        "plt.figure()\n",
        "plt.scatter(original_c[:,0], original_c[:,1],c=colours)\n",
        "colours[:] = np.array([1.0,0.0,0.0])\n",
        "plt.scatter(pts[:,0], pts[:,1],c=colours)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m.predict(inputs.reshape(1, 4, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Results\n",
        "\n",
        "* Even if the deviation can be trained, choosing a deviation that is too large, will result in odd behaviour.\n",
        "\n",
        "  To give an example, if we're trying to learn the _AND_ function, the output will contain more zeros than ones. Using gradient decent it is better to decrease the error by creating many zeros which is done by moving away the center instead of lowering the deviation. In testing, this often results in getting in a state which is badly trained, but we cannot get out of.\n",
        "\n",
        "* Training RBFs with multiple dense layers is less stable and will not converge as reliably using gradient decent. I believe this happens due to each RBF of lower levels 'prefering' a     different representation of the underlying feature space, and therefore no stable state is reached."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### First test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''Load data functions'''\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from typing import Tuple\n",
        "import pickle\n",
        "\n",
        "def load_mnist_csv(path:Path) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    '''\n",
        "    Returns:\n",
        "        labels, images\n",
        "    '''\n",
        "    raw_data:np.ndarray = np.loadtxt(path, delimiter=\",\")\n",
        "    indices = np.arange(raw_data.shape[0])\n",
        "    np.random.shuffle(indices)\n",
        "    return raw_data[indices,0].astype(int), raw_data[indices,1:] / 255.0\n",
        "\n",
        "def load_mnist_pickle(path:Path) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    with open(path, \"rb\") as f:\n",
        "        data = pickle.load(f)\n",
        "    return data[\"labels\"], data[\"data\"]\n",
        "\n",
        "def filter_mnist(data, labels, filter_id):\n",
        "    indices = np.where(labels==filter_id)\n",
        "    return data[indices], labels[indices]\n",
        "\n",
        "def create_one_hot_encoding(labels:np.ndarray)->np.ndarray:\n",
        "    '''\n",
        "    Creates a one hot encoding of the labels.\n",
        "\n",
        "    Assumes the labels start from 0.\n",
        "    '''\n",
        "    indices = np.empty((2, labels.shape[0]), dtype=int)\n",
        "    indices[0,:] = np.arange(labels.shape[0])\n",
        "    indices[1,:] = labels\n",
        "    num_labels = np.max(labels + 1)\n",
        "    encoded_labels = np.zeros((labels.shape[0], num_labels))\n",
        "    encoded_labels[indices[0], indices[1]] = 1.0\n",
        "    #encoded_labels = np.where(labels == 0, 1.0, 0.0).reshape(-1,1)\n",
        "    return encoded_labels\n",
        "\n",
        "def create_batches(data:np.ndarray, labels:np.ndarray, batch_size:int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    return data.reshape(-1, batch_size, data.shape[1]), labels.reshape(-1, batch_size, labels.shape[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''Load pickle data'''\n",
        "BATCH_SIZE: int = 500\n",
        "\n",
        "#Binary pickle files load much faster than the csv\n",
        "train_labels, train_data = load_mnist_pickle(Path(\"mnist_train.pickle\"))\n",
        "train_labels = create_one_hot_encoding(train_labels)\n",
        "\n",
        "validation_labels, validation_data = load_mnist_pickle(Path(\"mnist_test.pickle\"))\n",
        "validation_labels = create_one_hot_encoding(validation_labels)\n",
        "\n",
        "train_data, train_labels = create_batches(train_data, train_labels, BATCH_SIZE)\n",
        "validation_data, validation_labels = create_batches(validation_data, validation_labels, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''Load csv data'''\n",
        "BATCH_SIZE: int = 50\n",
        "\n",
        "train_labels, train_data = load_mnist_csv(Path(\"mnist_train.csv\"))\n",
        "train_labels = create_one_hot_encoding(train_labels)\n",
        "\n",
        "validation_labels, validation_data = load_mnist_csv(Path(\"mnist_test.csv\"))\n",
        "validation_labels = create_one_hot_encoding(validation_labels)\n",
        "\n",
        "train_data, train_labels = create_batches(train_data, train_labels, BATCH_SIZE)\n",
        "validation_data, validation_labels = create_batches(validation_data, validation_labels, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''Convert csv to pickle data'''\n",
        "import pickle\n",
        "\n",
        "\n",
        "train_labels, train_data = load_mnist_csv(Path(\"mnist_train.csv\"))\n",
        "with open(\"mnist_train.pickle\", \"wb\") as f:\n",
        "    pickle.dump({\"data\": train_data, \"labels\": train_labels}, f)\n",
        "\n",
        "validation_labels, validation_data = load_mnist_csv(Path(\"mnist_test.csv\"))\n",
        "with open(\"mnist_test.pickle\", \"wb\") as f:\n",
        "    pickle.dump({\"data\": validation_data, \"labels\": validation_labels}, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Model creation and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''Create a model'''\n",
        "from typing import List\n",
        "import numpy as np\n",
        "import layer\n",
        "import model\n",
        "from neurons import RBF\n",
        "import loss\n",
        "\n",
        "FIRST_LAYER_NEURONS:int = 1000\n",
        "SECOND_LAYER_NEURONS:int = 1200\n",
        "NUM_LABELS:int = train_labels.shape[2]\n",
        "\n",
        "layers:List[layer.DenseLayer] = []\n",
        "layers.append(layer.DenseLayer(train_data.shape[2], FIRST_LAYER_NEURONS, RBF()))\n",
        "layers.append(layer.DenseLayer(FIRST_LAYER_NEURONS, SECOND_LAYER_NEURONS, RBF()))\n",
        "layers.append(layer.DenseLayer(SECOND_LAYER_NEURONS, NUM_LABELS, RBF()))\n",
        "\n",
        "m = model.Model(layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''Create a model with smaller input regions'''\n",
        "from typing import List\n",
        "import numpy as np\n",
        "import layer\n",
        "import model\n",
        "from neurons import RBF\n",
        "import loss\n",
        "\n",
        "FIRST_LAYER_NEURONS:int = 25\n",
        "SECOND_LAYER_NEURONS:int = 20\n",
        "NUM_LABELS:int = train_labels.shape[2]\n",
        "\n",
        "train_data = train_data.reshape(-1, BATCH_SIZE, 28, 28)\n",
        "validation_data = validation_data.reshape(-1, BATCH_SIZE, 28, 28)\n",
        "\n",
        "layers:List[layer.DenseLayer] = []\n",
        "layers.append(layer.ConvolutionalLayer(train_data.shape, 2, 5, RBF()))\n",
        "lay: layer.ConvolutionalLayer = layers[-1]\n",
        "layers.append(layer.ConvolutionalLayer((1, BATCH_SIZE, lay.num_horizontal, lay.num_vertical), 2, 5, RBF()))\n",
        "lay: layer.ConvolutionalLayer = layers[-1]\n",
        "#layers.append(layer.ConvolutionalLayer((1, BATCH_SIZE, lay.num_horizontal, lay.num_vertical), 2, 3, RBF()))\n",
        "#lay: layer.ConvolutionalLayer = layers[-1]\n",
        "#layers.append(layer.DenseLayer(lay.num_horizontal * lay.num_vertical, FIRST_LAYER_NEURONS, RBF()))\n",
        "#layers.append(layer.DenseLayer(FIRST_LAYER_NEURONS, SECOND_LAYER_NEURONS, RBF()))\n",
        "#layers.append(layer.DenseLayer(SECOND_LAYER_NEURONS, NUM_LABELS, RBF()))\n",
        "layers.append(layer.DenseLayer(lay.num_horizontal * lay.num_vertical, NUM_LABELS, RBF()))\n",
        "\n",
        "m = model.Model(layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model for 100 epochs over 60000 training examples.\n",
            "Epoch 37/100 | Batch 35/120 | Average Error: 0.28 | 36% |████████████████████████████████████                                                                ||\r"
          ]
        }
      ],
      "source": [
        "'''Train the model.'''\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "TRAINING_REPITIONS:int = 100\n",
        "TRAIN_RATE:float = 0.001\n",
        "\n",
        "m.train(train_input=train_data, train_output=train_labels, epochs=TRAINING_REPITIONS, train_rate=TRAIN_RATE, loss_function=loss.quadratic_error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(np.array(m.losses), label=\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Average validation error: {m.validate(validation_data, validation_labels)}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting 10000 inputs.\n",
            "Batch 20/20 | 100% |████████████████████████████████████████████████████████████████████████████████████████████████████|\n",
            "Classified 6851 out of 10000 validation examples correctly.\n"
          ]
        }
      ],
      "source": [
        "def count_correct(input:np.ndarray, expected_labels:np.ndarray):\n",
        "    output = m.predict(input).reshape(-1, 10)\n",
        "    labels = np.argmax(output,axis=1)\n",
        "\n",
        "\n",
        "    mask = labels == np.argmax(expected_labels.reshape(-1,10),axis=1)\n",
        "\n",
        "    return np.sum(mask)\n",
        "    #return np.sum(np.abs(np.where(m.predict(input).flatten() >= 0.5, 1.0, 0.0) - expected_labels.flatten()))\n",
        "\n",
        "#print(f\"Classified {count_correct(train_data, train_labels)} out of {train_data.shape[0] * train_data.shape[1]} training examples correctly.\")\n",
        "print(f\"Classified {count_correct(validation_data, validation_labels)} out of {validation_data.shape[0] * validation_data.shape[1]} validation examples correctly.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def visualize_prototypes(rbf_weights:np.ndarray):\n",
        "    grey_scale_image = np.empty((*rbf_weights.shape, 3))\n",
        "    grey_scale_image[:,0] = rbf_weights\n",
        "    grey_scale_image[:,1] = rbf_weights\n",
        "    grey_scale_image[:,2] = rbf_weights\n",
        "    plt.figure()\n",
        "    plt.imshow(grey_scale_image.reshape(28, 28, 3))\n",
        "    plt.show()\n",
        "\n",
        "visualize_prototypes(m.layers[0].neurons.c[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import serialize\n",
        "\n",
        "serialize.serialize_model(m, \"model.pickle\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results show that these large dimensions heavly suffer from the vanishing gradient problem.\n",
        "\n",
        "Two ideas I have for solving this are:\n",
        "* BatchNorm layer\n",
        "    * I believe this may be counter productive for learning as we generally want to increase the diversity and not normalize this.\n",
        "    Although this may work in our favour since the network may be forced to create representations where the centers of a label are forced into different directions instead of just creating spacial distance.\n",
        "* Implement RPROP, which suffers less from vanishing gradient as it only considers the behaviour relating towards the sign of a gradient vector.\n",
        "* Make a \"fractal\" scheme where each neuron only learns a small dimensional subimage."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "yLnJEX22yzFJ"
      ],
      "name": "NeuroProjekt.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "545ce24e793e1353ad1aa1d336762d198a16bd057b21e3cc4f80d78d27aa7f07"
    },
    "kernelspec": {
      "display_name": "Python 3.7.10 64-bit ('test-env': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

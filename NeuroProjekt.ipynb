{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKBvoCq6sFLJ"
      },
      "source": [
        "# Basic imports and utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbfgCSeWsO6G"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import layer\n",
        "from neurons import RBF\n",
        "from typing import List\n",
        "import loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLnJEX22yzFJ"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpYFiq29yw9r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-tGOT28rRvg"
      },
      "source": [
        "# RBF\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pIypjUCx6VG"
      },
      "source": [
        "We choose a gau√üian activation function for a RBF neuron with it's derivatives $$y(x)=e^{-\\frac{||x - c||^2}{2\\sigma^2}}$$\n",
        "$$\\frac d{dc}y(x)=\\frac{x-c}{\\sigma^2}e^{-\\frac{||x - c||^2}{2\\sigma^2}}$$\n",
        "$$\\frac d{dx}y(x)=-\\frac{x-c}{\\sigma^2}e^{-\\frac{||x - c||^2}{2\\sigma^2}}$$\n",
        "\n",
        "The standard deviation is going to be a fixed size hyper parameter.\n",
        "## Definition of an RBF in this module\n",
        "To use the broadcasting abilities of numpy as much as possible, we design functions in a way that they can update multiple neurons at once. For this we design the data structures for our neurons in a data oriented way. For this to work, the only limit put onto our neurons is that the input dimensions should be the same for all neurons.\n",
        "\n",
        "Since we are going to work on images, and an image is a $(w, h, 3)$ float or integer array an RBF neuron needs to define the following things.\n",
        "\n",
        "c: Should be a $(k_w, k_h, k_c)$ array representing the centers for this neuron\n",
        "\n",
        "x: A subimage that should be defined by the outside function with the same dimesnions as c."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_RATE:float = 0.1\n",
        "TRAIN:bool = True\n",
        "FIRST_LAYER_NEURONS:int = 3\n",
        "TRAINING_REPITIONS:int = 100\n",
        "\n",
        "layers:List[layer.DenseLayer] = []\n",
        "layers.append(layer.DenseLayer(2, FIRST_LAYER_NEURONS, RBF))\n",
        "layers.append(layer.DenseLayer(FIRST_LAYER_NEURONS, 1, RBF))\n",
        "\n",
        "#layers[0].neuron_data = np.array([[0.0,0.0], [1.0,0.0], [0.0,1.0]])\n",
        "#layers[1].neuron_data = np.array([[0.0,0.0,0.0]])\n",
        "\n",
        "inputs = np.array([[0.0,0.0],[1.0,0.0],[0.0,1.0],[1.0,1.0]])\n",
        "expected = np.array([0.0,1.0,1.0,1.0])\n",
        "\n",
        "losses = []\n",
        "errors = []\n",
        "\n",
        "if TRAIN:\n",
        "    for _ in range(TRAINING_REPITIONS):\n",
        "        order = np.arange(4)\n",
        "        np.random.shuffle(order)\n",
        "        for i in range(4):\n",
        "            current_input = inputs[order[i]]\n",
        "            for l in layers:\n",
        "                current_input = l.propagate(current_input)\n",
        "            errors.append(np.abs(expected[order[i]] - current_input[0]))\n",
        "            loss_i, deriv = loss.quadratic_error(current_input[0], expected[order[i]])\n",
        "            losses.append(loss_i)\n",
        "\n",
        "            deriv = layers[1].back_propagate(deriv, TRAIN_RATE)\n",
        "            deriv = layers[0].back_propagate(deriv, TRAIN_RATE)\n",
        "\n",
        "    plt.plot(errors, label='Error')\n",
        "    plt.plot(losses, label='Loss')\n",
        "    plt.legend()\n",
        "\n",
        "for i in range(4):\n",
        "    current_input = inputs[i]\n",
        "    for l in layers:\n",
        "        current_input = l.propagate(current_input)\n",
        "    print(f\"Output: {current_input[0]}\\tExpected: {expected[i]}\")\n",
        "\n",
        "pts = np.empty((FIRST_LAYER_NEURONS, 2))\n",
        "colours = np.empty((FIRST_LAYER_NEURONS,3))\n",
        "pts = layers[0].neuron_data\n",
        "colours[:] = np.array([1.0,0.0,0.0])\n",
        "plt.figure()\n",
        "plt.scatter(pts[:,0], pts[:,1],c=colours)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "yLnJEX22yzFJ"
      ],
      "name": "NeuroProjekt.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "545ce24e793e1353ad1aa1d336762d198a16bd057b21e3cc4f80d78d27aa7f07"
    },
    "kernelspec": {
      "display_name": "Python 3.7.10 64-bit ('test-env': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
